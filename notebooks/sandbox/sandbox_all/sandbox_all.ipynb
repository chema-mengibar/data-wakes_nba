{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Snippets (donÂ´t run this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import urllib, base64\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json \n",
    "from pandas.io.json import json_normalize \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import cm\n",
    "from matplotlib import colors as mcolors\n",
    "import re\n",
    "from decimal import Decimal\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read JSON File\n",
    "\n",
    "with open('../../data/dir1/file-name.json') as f: \n",
    "    content = json.load(f)\n",
    "  \n",
    "content['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save JSON File\n",
    "\n",
    "_notebook_folder = 'block-000'\n",
    "_version = '1.0'\n",
    "\n",
    "dirPath = '../../data/master/dir1/'\n",
    "fileName = f'{_notebook_folder}-{_version}.json'\n",
    "\n",
    "fullPath = dirPath + fileName\n",
    "with open( fullPath, 'w') as outfile:\n",
    "    json.dump(data, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_sprintNumber' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6fc927837810>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0m_version\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'1.0'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdirPath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../../data/master/dir1/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfileName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'prefix__name-{_sprintNumber}.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mproductFullPath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproductPath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mproductFileName\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '_sprintNumber' is not defined"
     ]
    }
   ],
   "source": [
    "# Read CSV\n",
    "\n",
    "_version = '1.0'\n",
    "dirPath = '../../data/master/dir1/'\n",
    "fileName = f'prefix__name-{_version}.csv'\n",
    "\n",
    "fullPath = dirPath + fileName\n",
    "\n",
    "plotDf = pd.read_csv( fullPath ) \n",
    "plotDf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 > 6\n"
     ]
    }
   ],
   "source": [
    "# Loop\n",
    "tasks = [1,2,3,4,0,1,2,0]\n",
    "taskNoEmptys = [task for task in tasks if task > 0 ]\n",
    "\n",
    "print( len(tasks),'>' , len(taskNoEmptys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exec \n",
    "\n",
    "emptyList = []\n",
    "\n",
    "for item in fullList:\n",
    "    resultItem = doSomething(item)\n",
    "    try:\n",
    "        result = doSomethingElse(resultItem)\n",
    "        emptyList.append( result )\n",
    "    except Exception as e:\n",
    "        print('ERROR in ',item, e)\n",
    "\n",
    "emptyList[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Javascript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "// var nbPathParts = IPython.notebook.notebook_path.split('/')\n",
    "//var nbFolder = nbPathParts[ nbPathParts.length - 2]\n",
    "//IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n",
    "//IPython.notebook.kernel.execute('nb_folder = \"' + nbFolder + '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Save\n",
    "%store myVariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Read\n",
    "\n",
    "%store -r\n",
    "# myVariable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse\n",
    "def parseJsonToDf( jsonPicEntry, idx ):\n",
    "    df = json_normalize( data=jsonTaskEntry['status'], meta=[ 'statusName','statusId','date','sp',] )\n",
    "    # date = df.groupby('date').last().index[0]\n",
    "    # df['_task_idx'] = idx\n",
    "    # df['sp'] = jsonTaskEntry['sp']\n",
    "    # df['author'] = jsonTaskEntry['author']\n",
    "    # df['_plt_pos_X'] = df.sp.astype('float') \n",
    "    # df['_plt_pos_x'] = df.groupby(['sprintDay','task']).cumcount()\n",
    "    # df['_plt_width'] = 1/df.groupby('date')['date'].transform('count').astype('int')\n",
    "    # df['_plt_division'] = df.groupby('date')['date'].transform('count').astype('int')\n",
    "    return df\n",
    "\n",
    "dataFrames = [ parseJsonToDf(jsonItem, idx) for idx, jsonItem in enumerate(parseJSONFileContent) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat\n",
    "dfAll = pd.concat(dataFrames).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append\n",
    "dfBuffer = pd.DataFrame(data=None, columns=dfTarget.columns, index=dfTarget.index).dropna()\n",
    "\n",
    "listOfSeries = []\n",
    "\n",
    "def addToList( valuesList ):\n",
    "    listOfSeries.append( pd.Series( valuesList, index=dfBuffer.columns )  )\n",
    "    \n",
    "def addRawToList( row ):\n",
    "    listOfSeries.append( row )\n",
    "\n",
    "def addListToDfRows():\n",
    "    # print('##########', len(listOfSeries))\n",
    "    # Pass a list of series to the append() to add multiple rows\n",
    "    dfBuffer01 = dfBuffer.append(listOfSeries , ignore_index=True)\n",
    "    return dfBuffer01\n",
    "\n",
    "## Test\n",
    "# addToList( ['a', 1, 1, 1,0,'ABC',7,1,0.0,0,1.00,1] )\n",
    "# newDF = addListToDfRows()\n",
    "# newDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterator ???\n",
    "\n",
    "row_iterator = dfTarget.iterrows()\n",
    "_, nrow  =  next(row_iterator)  # take first item from row_iterator\n",
    "\n",
    "for idx, row in row_iterator:\n",
    "    #print( row['columName'], row['date'] , nrow['date'] ) # issue with last sprint pics\n",
    "    \n",
    "    nextPointer = datesList[0] if row['date'] < datesList[0] else row['date']\n",
    "    lastPointer = datesList[0] if nrow['date'] < datesList[0] else nrow['date']\n",
    "    lastDayStatus = diffDays(lastPointer, nextPointer )\n",
    "    \n",
    "    if row['columName'] == nrow['columName'] and lastDayStatus > 1: # Create a needed row\n",
    "        #print('---- direfence', lastDayStatus)\n",
    "        for d in range(1,lastDayStatus):\n",
    "            ghostRow = nrow.copy()\n",
    "            ghostRow['_gen'] = 1\n",
    "            print( ghostRow )\n",
    "            addRawToList(ghostRow)\n",
    "    nrow = row\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort \n",
    "#.sort_values(by=['date', 'ref'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort \n",
    "dfFull = pd.concat([dfTarget,newDF])\n",
    "dfFullSorted = dfFull.sort_values(by=['author','ref','sprintDay','status']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ressources\n",
    "\n",
    "\n",
    "- https://realpython.com/python-data-visualization-bokeh/\n",
    "- https://jakevdp.github.io/PythonDataScienceHandbook/04.09-text-and-annotation.html\n",
    "- https://stackoverflow.com/questions/47373762/pyplot-sorting-y-values-automatically\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
